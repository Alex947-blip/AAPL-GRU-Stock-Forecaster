# ğŸ AAPL Stock Price Forecasting Project

## ğŸ¯ Project Overview

This project implements an end-to-end Machine Learning solution for forecasting the closing price of Apple stock (AAPL) using a Gated Recurrent Unit (GRU) neural network. The entire pipeline, from raw data ingestion and cleaning to model training and evaluation, is containerized and follows a strict modular structure for reproducibility.

The final model successfully achieved a **Mean Absolute Percentage Error (MAPE)** of **0.27%** for the 1-Day forecast, validating the deep learning approach for time series prediction.

---

## ğŸ“ Project Structure

The repository is organized following industry standards for data science projects, ensuring clear separation between code, data, models, and documentation.

<pre lang="markdown">
AAPL_Forecast_Project/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Contains the raw input data (e.g., AAPL_historical.csv)
â”‚ â””â”€â”€ processed/ # Stores the clean, serialized TimeSeries objects (.pkl files)
â”œâ”€â”€ models/ # Stores the final trained Darts/PyTorch models (.pkl files)
â”œâ”€â”€ notebooks/ # Contains exploratory and final reporting notebooks
â”œâ”€â”€ src/ # Source code for the production pipeline
â”‚ â”œâ”€â”€ data_pipeline.py # Data fetching, cleaning, and TimeSeries preparation
â”‚ â””â”€â”€ forecasting_model.py # Model definition, training, and evaluation
â”œâ”€â”€ .venv/ # Python virtual environment
â”œâ”€â”€ run_all.ps1 # PowerShell automation script to run the full pipeline.
â”œâ”€â”€ README.md # This file
â””â”€â”€ requirements.txt # List of project dependencies
</pre>

---

## ğŸ› ï¸ Prerequisites

To run this project locally, you must have **Python 3.8+** and a PowerShell environment (standard on Windows) or access to the respective PowerShell Core tools on other platforms.

1. Â **Clone the Repository:**
Â  Â  ```
Â  Â  git clone [https://github.com/HenryMorganDibie/AAPL-GRU-Stock-Forecaster.git](https://github.com/HenryMorganDibie/AAPL-GRU-Stock-Forecaster.git)
Â  Â  cd AAPL_Forecast_Project
Â  Â  ```

2. Â **Set up the Environment:**
Â  Â  ```
Â  Â  python -m venv .venv
Â  Â  .\.venv\Scripts\activate Â # Windows
Â  Â  # source .venv/bin/activate Â # macOS/Linux
Â  Â  ```

3. Â **Install Dependencies:**
Â  Â  ```
Â  Â  pip install -r requirements.txt
Â  Â  ```

---

## ğŸ§  Model & Strategy Deep Dive (Justification)

This section details the choices made regarding the data structure, model architecture, and multi-horizon forecasting strategy, fulfilling the requirement for technical justification.

### 1. Feature Engineering and Rationale

The project focuses on **univariate time series forecasting**, using only historical closing prices for prediction.

| Feature | Type | Rationale |
| :--- | :--- | :--- |
| **Close Price (Input)** | Univariate | Primary target variable and input feature. Establishes a strong *autoregressive* baseline using only past price movements. |
| **Open, High, Low, Volume** | Ignored | Excluded to minimize noise and complexity. Future work can incorporate these as **covariates** for improved trend capture. |

### 2. Darts Framework and Model Implementation

The **Darts** framework was utilized to provide a clean, production-ready interface for deep learning time series models:

* **Data Preparation:** The `TimeSeries` object handles data indexing and frequency (`freq='B'`) automatically.
    ```python
    from darts import TimeSeries
    # Creates Darts object with DatetimeIndex
    series = TimeSeries.from_dataframe(series_df, freq='B') 
    ```
* **Model Instantiation:** The core model is an implementation of the **RNNModel** class from Darts, set to use the GRU architecture.
    ```python
    from darts.models import RNNModel
    # Model uses 30 days of input to predict 21 days out
    model = RNNModel(
        model='GRU', 
        input_chunk_length=30, 
        output_chunk_length=21, # Multi-step prediction length
        n_epochs=200
    )
    ```

### 3. Multi-Horizon Forecasting Strategy

- **GRU vs. LSTM Comparison**: I performed a preliminary comparison between the GRU and LSTM architectures. The Gated Recurrent Unit (GRU) was chosen because it offered comparable prediction accuracy (MAPE scores) to the more complex LSTM but achieved faster convergence and required fewer trainable parameters. This prioritized model efficiency and simplicity for the final production baseline.

**Forecasting Strategy (Direct Multi-step)**: I employed a **Direct Multi-step Forecasting** approach:

* **Single Model Training:** Only **one** GRU model was trained.
* **Unified Output:** The model was configured with an `output_chunk_length` of **21** (the longest required horizon).
* **Evaluation:** The single 21-day forecast vector generated by the model is evaluated at three distinct time steps:
    * **1 Day Ahead** (Index 0 of the forecast vector)
    * **1 Week Ahead (5 Days)** (Index 4 of the forecast vector)
    * **1 Month Ahead (21 Days)** (Index 20 of the forecast vector)
* **Rationale:** This method ensures temporal consistency across all horizons and avoids the computational cost of training multiple models.

### 4. Data Splitting and Validation

* **Time-Based Split:** A strictly **chronological split** was used to prevent **look-ahead bias** (data leakage).
* **Split Ratios:** The overall dataset (2015-present) was split as follows:
    * **Train Set:** All data up to approximately **2 years before the current date**.
    * **Validation Set:** The **final 252 trading days** (approx. 1 year) of data, used for final metric reporting.
* This approach isolates the validation set to ensure the model is evaluated only on future data it has never observed.

---

## ğŸš€ How to Run the Project (Automated)

The entire project pipelineâ€”data preparation, model training, and savingâ€”can be executed from your PowerShell terminal using the dedicated automation script.

**Note:** Ensure your virtual environment (`.venv`) is activated before running.

### Single-Step Execution (Recommended)

```bash
.\run_all.ps1
```

This script will sequentially:

- Confirm the virtual environment is active.

- Execute src/data_pipeline.py.

- Execute src/forecasting_model.py.

- Output the final MAPE metrics to the console.


**Manual Execution (For Debugging or Development)**

**For development or debugging purposes, you can run the steps individually:**

### Step 1: Data Pipeline Execution

This script fetches the latest AAPL data, cleans it, and splits it into training and validation TimeSeries objects, saving them to `data/processed/`.

```bash
python src/data_pipeline.py
```

### Step 2: Model Training and Saving
This script loads the processed data, scales it, trains the optimized GRU model, performs inverse scaling, and calculates the final MAPE metrics before saving the model artifact to models/.

```bash
python src/forecasting_model.py
```

### Step 3: Final Reporting (Jupyter Notebooks)To view the detailed data analysis and model performance visualization, open the Jupyter notebooks:

- 01_EDA_Preprocessing.ipynb: Review the data cleaning process and initial time series plots

- 02_Model_Training_Evaluation.ipynb: Load the saved model, regenerate the final forecast, and analyze the results, including the key MAPE scores and the Actual vs. Predicted Price Plot.

### ğŸ“Š Key Results and Limitations

#### Final MAPE Performance
The model's error naturally increases as the forecast horizon extends â€” this is expected due to the error accumulation inherent in time-series forecasting.

| Horizon               | Mean Absolute Percentage Error (MAPE) | Performance Description                                           |
|------------------------|----------------------------------------|-------------------------------------------------------------------|
| 1 Day Ahead            | 0.2726%                               | Exceptional accuracy for short-term trading.                      |
| 1 Week Ahead (5 Days)  | 1.0403%                               | Highly reliable over a business week.                             |
| 1 Month Ahead (21 Days)| 4.1789%                               | Strong, maintaining error under the 5% threshold, demonstrating long-term predictive strength. |

---

### Project Limitations and Future Work

- **Exogenous Factors:**  
  The current univariate model does not account for critical external variables (e.g., macroeconomic indicators, volume, market sentiment).  
  Future work should integrate these as exogenous regressors within the Darts framework.

- **Model Robustness:**  
  The model is trained on a fixed historical window.  
  For production use, implementing **rolling window retraining** would be necessary to adapt to recent market shifts and maintain performance over time.

---

## ğŸ“ Final Reporting (Jupyter Notebooks)

To view the detailed data analysis, model performance visualization, and complete justification report, open the following Jupyter notebooks:

1. **`01_EDA_Preprocessing.ipynb`**  
   Review the data cleaning process and initial time series plots.

2. **`02_Model_Training_Evaluation.ipynb`**  
   Load the saved model, regenerate the final forecast, and analyze the results â€” including key MAPE scores and the Actual vs. Predicted Price Plot.

3. **`placeholder.txt`**
   Project Conclusion
